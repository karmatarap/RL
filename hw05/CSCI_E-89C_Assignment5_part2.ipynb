{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Karma Tarap\n",
    "### CSCI E-89C Deep Reinforcement Learning  \n",
    "### Part II of Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem we consider patients with end-stage liver disease (ESLD). We assume that patient's health condition is fully characterized by the Model for End-stage Liver Disease (MELD) score (Jae-Hyeon Ahn and John Hornberger, Involving patients in the cadaveric kidney transplant allocation process: a decision-theoretic perspective. Manage Sci. 1996;42(5):629–41).\n",
    "\n",
    "The MELD score ranges from 6 to 40 and is derived based on the probability of survival at 3 months for patients with ESLD. Data in ESLD is usually sparse and often aggregated into Stages. We assume that there are 18 stages based on the ESLD: Stage 1, Stage2, ..., Stage 18. The time step is 1 year and the actions in Stages 1 through 18 are \"wait\" (denoted by 0) and \"transplant\" (denoted by 1). \n",
    "\n",
    "We assume that the Markov property holds. There are two additional states of the Markov Decision Process: \"Posttransplant Life\" (denoted by 19) and \"Death\" (which is denoted by 20 and combines so caled \"Pretransplant Death\" and \"Posttransplant Death\"). The only action availible in state \"Posttransplant Life\" is \"wait\" and \"Death\" is the terminal state with no actions. Assume that the length of an episode is T=49, unless it terminates earlier due to the transition to the absorbing state \"Death.\"\n",
    "\n",
    "We do not know the transition probabilities, but if a patient selects \"wait,\" the possible transitions are   \n",
    "1) Stage 1->Stage 1, Stage 1->Stage 2, Stage 1->Death  \n",
    "2) For k in {2,3,4,...17}, Stage k->Stage (k-1), Stage k->Stage k, Stage k->Stage (k+1), Stage k->Death    \n",
    "3) Stage 18->Stage 17, Stage 18->Stage 18, Stage 18->Death    \n",
    "\n",
    "If a patient selects \"transplant\" at Stage k, k=1,2,...,18, the only possible transition is  \n",
    "4) Stage k->\"Posttransplant Life\"\n",
    "\n",
    "Finally, there are two more possible transitions\"  \n",
    "5) \"Posttransplant Life\"->\"Posttransplant Life\" and \"Posttransplant Life\"->\"Death\"  \n",
    "\n",
    "\n",
    "The patient gets reward 1 in all states \"Stage k\" (k=1,2,...,18) and reward 0.2 in the \"Posttransplant Life\" state - assume that the patient gets these rewards on \"exit\" from the states, i.e. after we observe the corresponding stage. We assume the discounting parameter $\\gamma=0.97$, one of the most common discounting rate used in medical decision making (Gold MR, Siegel JE, Russell LB, Weinstein MC. Cost-Effectiveness in Health and Medicine. Oxford University Press; New York: 1996).\n",
    "\n",
    "\n",
    "Please consider statistics on 8,000 patients with ESLD saved in the 'ESLD_statistics.csv' file. Each row represents an episode (i.e. one patient) and the columns are the sequences of the patients' states and actions. This data were generated under the behavior policy:\n",
    "\n",
    "$b(1|k)=0.02$ for $k\\in\\{1,2,3,4,5,6,7,8,9,10,11,12,13\\}$;   \n",
    "$b(1|14)=0.05$;   \n",
    "$b(1|15)=0.10$;   \n",
    "$b(1|16)=0.20$;   \n",
    "$b(1|17)=0.40$;  \n",
    "$b(1|18)=0.60$;  \n",
    "\n",
    "which means that, for example, 5% of paients at stage 14 received a transplant.\n",
    "\n",
    "   \n",
    "Please use the Off policy MC control (for estimating $\\pi_*$), which corresponds to the weighted importance sampling, to obtain the optimal policy. Please be specific and answer at what stages it is worth considering a transplant and at which stages - not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S0</th>\n",
       "      <th>A0</th>\n",
       "      <th>S1</th>\n",
       "      <th>A1</th>\n",
       "      <th>S2</th>\n",
       "      <th>A2</th>\n",
       "      <th>S3</th>\n",
       "      <th>A3</th>\n",
       "      <th>S4</th>\n",
       "      <th>A4</th>\n",
       "      <th>...</th>\n",
       "      <th>A45</th>\n",
       "      <th>S46</th>\n",
       "      <th>A46</th>\n",
       "      <th>S47</th>\n",
       "      <th>A47</th>\n",
       "      <th>S48</th>\n",
       "      <th>A48</th>\n",
       "      <th>S49</th>\n",
       "      <th>A49</th>\n",
       "      <th>S50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   S0  A0  S1  A1  S2  A2  S3  A3  S4  A4  ...  A45  S46  A46  S47  A47  S48  \\\n",
       "0  12   0  12   0  13   0  13   0  20   0  ...    0   20    0   20    0   20   \n",
       "1   3   0   3   0   3   0   3   0   3   0  ...    0   20    0   20    0   20   \n",
       "2  16   0  16   0  16   1  19   0  19   0  ...    0   20    0   20    0   20   \n",
       "3  13   0  13   0  13   0  13   0  14   0  ...    0   20    0   20    0   20   \n",
       "4   4   0   4   0   4   0  20   0  20   0  ...    0   20    0   20    0   20   \n",
       "\n",
       "   A48  S49  A49  S50  \n",
       "0    0   20    0   20  \n",
       "1    0   20    0   20  \n",
       "2    0   20    0   20  \n",
       "3    0   20    0   20  \n",
       "4    0   20    0   20  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data and take a peek\n",
    "elsd = pd.read_csv(\"ESLD_statistics.csv\")\n",
    "elsd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(state):\n",
    "    \"\"\"\n",
    "    The patient gets reward 1 in all states Stage k (k=1,2,...,18) and \n",
    "    reward 0.2 in the \"Posttransplant Life\n",
    "    \n",
    "    Args: \n",
    "        state: current state\n",
    "    \n",
    "    Returns: \n",
    "        Reward associated with exiting state,\n",
    "    \"\"\"\n",
    "    if state < 18:\n",
    "        reward = 1.\n",
    "    elif state == 18:\n",
    "        reward = 0.2\n",
    "    else:\n",
    "        reward = 0.\n",
    "    return reward \n",
    "\n",
    "\n",
    "def b(state, action):\n",
    "    \"\"\"\n",
    "    Mapping of state and action to probability of action given state\n",
    "    for behaviour policy. Transition probabilities taken from notebook.\n",
    "    \n",
    "    Args:\n",
    "        state: current state\n",
    "        action: current action\n",
    "        \n",
    "    Returns:\n",
    "        Probability of action given state.\n",
    "    \"\"\"\n",
    "    # placeholder probabilities of 0 added for post-transplant and death\n",
    "    transplant_pr = [.02 for i in range(13)] + [.05, .1, .2, .4, .6, 0., 0.]\n",
    "    return transplant_pr[state] if action == 1 else 1-transplant_pr[state]\n",
    "    \n",
    "\n",
    "def monte_carlo_control(data=elsd, gamma=0.97, T=49):\n",
    "    \"\"\"\n",
    "    Implementation of `Off policy for MC control for estimating π \\sim \\pi_*` \n",
    "    algorithm from Reinforcement Learning Book (page 111),\n",
    "    \n",
    "    Args:\n",
    "        data: pandas dataframe containing sequences as rows.\n",
    "        gamma: discount parameter\n",
    "        T: Length of episodes to consider\n",
    "        \n",
    "    Returns:\n",
    "        π: Estimate of optimal policy $\\pi_*$\n",
    "        q: State Action Value matrix\n",
    "    \"\"\"\n",
    "    # 20 states, 2 actions\n",
    "    C = np.zeros((20, 2))\n",
    "    Q = np.zeros((20, 2))\n",
    "    \n",
    "    # Greedy policy of target policy\n",
    "    π = np.argmax(Q, axis=1)\n",
    "\n",
    "    for index, episode in data.iterrows():\n",
    "        # States and actions are concurrent, extracting into \n",
    "        # separate lists\n",
    "        states = episode[::2]\n",
    "        actions = episode[1::2]\n",
    "        \n",
    "        G = 0 # Sum of discounted rewards\n",
    "        W = 1 # Importance sampling ratio weights\n",
    "        \n",
    "        # Traversing backward through timestep T-1 to t\n",
    "        for t in reversed(range(0,T)):\n",
    "            # Only update from first death record\n",
    "            #if states[t-1] == 20:\n",
    "            #    continue\n",
    "            \n",
    "            # 0-indexing states for easier use with arrays\n",
    "            S, A = states[t]-1, actions[t]\n",
    "            R = get_reward(S)\n",
    "            G = gamma*G + R  \n",
    "            C[S, A] += W\n",
    "            Q[S, A] += (W / C[S, A]) * (G - Q[S, A])\n",
    "            \n",
    "            π[S] = np.argmax(Q[S])\n",
    "\n",
    "            if A !=  π[S]:\n",
    "                break\n",
    "            W *= (1 / b(S, A)) \n",
    "    return π, Q\n",
    "\n",
    "policy, q = monte_carlo_control()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our estimate of $\\pi_*$ we should not transplant unless we are in stage 17 or 18 of the disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
